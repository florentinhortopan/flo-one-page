
---
title: "Designing for Intelligence: UX and AX in AI Products"
author: "Florentin Hortopan"
date: "2025-10-23"
---

# Designing for Intelligence: UX and AX in AI Products

In an era where interfaces are no longer static, but dynamic, intelligent, and responsive, my work focuses on reshaping how humans interact with AI-powered systems. With over two decades of design experience and a deep grounding in design systems, Iâ€™ve come to see the evolution from user experience (UX) to what I call **Agent Experience (AX)** as essential for building meaningful products.

## From User Experience (UX) to Agent Experience (AX)

This shift moves us beyond traditional UXâ€”where humans interface with softwareâ€”to **AX**, where users interface with systems that act *on their behalf*. The relationship between user and interface becomes more collaborative, more emergent. Rather than pressing buttons and waiting for results, users engage with **agents** that interpret intent, adapt behavior, and make autonomous decisions.

### "Design is no longer about control panels. It's about conversation, context, and co-evolution."

AX isnâ€™t about replacing UI with chatbots or hiding complexity behind AIâ€”itâ€™s about:

- **Maintaining legibility and control in agent-driven workflows**
- **Creating systems that learn transparently**
- **Balancing initiative between user and AI**
- **Designing with and for context-aware behavior**

## Core UX Principles in the Age of AI

My UX philosophy draws inspiration from Doug Engelbartâ€™s vision of augmenting human intellect, John Seely Brownâ€™s ideas on tacit knowledge, and modern human-centered AI research. These are the pillars I follow when designing intelligent systems:

### 1. **Outcome-Oriented Design**
Inspired by research in generative UI and LLM-driven design, I emphasize focusing on the *user's desired outcome*, not just the task. Interfaces should help users clarify and achieve goalsâ€”not just operate tools.

> "Ask what success *feels* like for the user, then sculpt the interface backward from that moment."

### 2. **Progressive Disclosure of Intelligence**
AI shouldnâ€™t overwhelm users with autonomous actions. I design systems that **reveal capability over time**, allowing users to build confidence and mental models. This supports trust and reduces the "cold start" problem of open-ended interfaces.

### 3. **Clarity Before Cleverness**
Whether itâ€™s in-app guidance, semantic design tokens, or dynamic calendars, I favor **legibility and predictability** over novelty. AI can surpriseâ€”but never confuse.

### 4. **Tool Thinking vs. Agent Thinking**
Borrowing from Engelbart, I distinguish between *tools that extend ability* and *agents that act for you*. Good AI design makes this distinction clear. Users should always know: Am I commanding a tool, or collaborating with an agent?

### 5. **Systemic Design Thinking**
My background in design systems informs my ability to think modularly. In AI-driven UX, this means designing adaptable **building blocks** that agents can assemble and modify in real time, without sacrificing consistency.

## Real-World Practice: At the Edge of AI x UX

Some recent work includes:

- Building LLM-enhanced design system tools for internal use at Airbnb
- Creating urgency-based notification dashboards to avoid cognitive overload
- Mentoring teams in outcome-first design for in-app AI guidance
- Driving compliance and accessibility as foundationalâ€”not optionalâ€”in intelligent systems

Design leadership bridges front-end, back-end, and human intention, enabling a more integrated and humane AI product experience.

## Toward Humane Generative Interfaces

As the field of **Generative UI** evolves, I remain cautious but optimistic. Drawing on research in dynamic UI generation, I warn against interfaces that are "too universal" or context-shifting to the point of unpredictability.

> "Generative doesn't mean chaotic. It means *tailored*, like a suitâ€”cut to fit, not cut to confuse."

A better future for interfaces means:

- Reacting to user intent in real time (LLM-powered responsiveness)
- Revealing system reasoning when needed (explainability for trust)
- Allowing override and correction (co-agency)
- Being inclusive by default, accounting for cognitive, motor, and linguistic diversity

## Conclusion: A Philosophy of Co-Evolution

This philosophy isnâ€™t just about UX or AXâ€”itâ€™s about **co-evolution**. As tools become agents, and agents become collaborators, designers must help users grow alongside them. That means clarity, respect, and deeply contextual interfaces that elevate human potential without disempowering it.

> "Great design doesnâ€™t just answer the userâ€”it grows with them."

---

ðŸ“¬ For speaking, consulting, or collaboration inquiries, reach me at [flo@puxa.ai](mailto:flo@puxa.ai).

ðŸ”— [www.florentin.us](https://www.florentin.us) (password upon request)

ðŸ“– Read more reflections: [Medium @panopano](https://medium.com/@panopano)
